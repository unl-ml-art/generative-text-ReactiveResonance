{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7LoMj4GA4n_"
   },
   "source": [
    "#  GPT-2 Generation and Fine-Tuning\n",
    "\n",
    "This notebook explores GPT-2 (Generative Pretrained Transformer-2) from OpenAI. Read more about it [here](https://openai.com/blog/better-language-models/).\n",
    "\n",
    "Activities include:\n",
    "\n",
    "0. Setup\n",
    "1. Generate samples from pre-trained gpt-3 model\n",
    "2. Fine-tune gpt-2 on text of your choosing. \n",
    "\n",
    "Adapted by Robert Twomey (rtwomey@unl.edu) for Machine Learning for the Arts SP22 from this [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) by [Max Woolf](http://minimaxir.com). See his repo [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run once to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q gpt-2-simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart the kernel and run the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KBkpRgBCBS2_"
   },
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj2IJLHP3KwE"
   },
   "source": [
    "## GPU\n",
    "\n",
    "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
    "\n",
    "You can verify which GPU is active by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUmTooTW3osf",
    "outputId": "c9fcfa4f-277d-4b3e-8974-373066dc157b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 22 02:42:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    28W / 250W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the memory usage (0MiB / 32510MiB) for the Tesla V100.\n",
    "You can re-rerun the above cell to see what memory your code/models are using during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wXB05bPDYxS"
   },
   "source": [
    "## Downloading GPT-2\n",
    "\n",
    "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
    "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
    "\n",
    "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
    "\n",
    "The next cell downloads it from Google Cloud Storage and saves it in the the current working directory at `/models/<model_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "10fc0d7c-d18f-4e11-a2af-bfade8b537eb"
   },
   "outputs": [],
   "source": [
    "model_name = \"355M\" # largest model we can fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run once to download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 760Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 4.18Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 882Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:23, 61.0Mit/s]                                 \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 842Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.22Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 6.09Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQAN3M6RT7Kj"
   },
   "source": [
    "# 1. Generate Text From The Pretrained Model\n",
    "\n",
    "If you want to generate text from the pretrained model pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`. (This is currently the only way to generate text from the 774M or 1558M models with this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "BAe4NpKNUj2C",
    "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 02:44:07.358167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 02:44:08.048017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.load_gpt2(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the model\n",
    "The follow cell samples from gpt-2, using the provided prefix (seed) and other parameters. It starts the TF session and generates the samples.\n",
    "\n",
    "Try changing the parameters below to change the output: \n",
    "- `prefix` is the prompt. This will be the starting string/seed for your generation. Use your own text. \n",
    "- `temperature` sets the variability/randomness of the output. Range 0.0-1.0\n",
    "- `length` sets the lenght of output (in tokens). max is 1024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "-xInIZKaU104",
    "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my last straw. I've been trying to get through the day without talking to anyone in the hospital. I just wanted to be able to go home to my family and have my dad and sister come visit me. I'm just so upset.\"\n",
      "\n",
      "He added: \"I was just trying to make it through, but I've had to tell my sister, 'I'm sorry, I'm just so sorry.' It's like, 'You're not a bad person, you're just trying to live your\n",
      "====================\n",
      "This is my last straw! I'm done with this! I can't live with this!\"\n",
      "\n",
      "\"They're not having a party here!\"\n",
      "\n",
      "\"I'm going to get myself out of here!\"\n",
      "\n",
      "\"You can't leave! I'm going to fight you! I'm going to fight you!\"\n",
      "\n",
      "\"I don't want to be here! I don't want to be here!\"\n",
      "\n",
      "\"You're not going to leave me here!\"\n",
      "\n",
      "\"I don't want to be\n",
      "====================\n",
      "This is my last straw. I didn't want to be a prostitute and I didn't want to be on camera. I'm still in shock and I'm not sure what I'll do next. I'm still on drugs, I still drink, I still smoke. I'm still the same person. I'm not going to give up, I'm not going to give in. I'm not going to go through this again.\n",
      "\n",
      "\"I don't have any friends anymore, I'm not going to go back\n",
      "====================\n",
      "This is my last straw. The challenge I put myself on was to get back to the way I was before. I'm not going to continue to get back to that level. That's not who I am.\n",
      "\n",
      "\"I'm not going to put myself through that again.\"\n",
      "\n",
      "The injury-plagued 10-year veteran spent the first six months of the season on the sidelines, missing six games. He did return to the field for the final five games, but played just 31 minutes in those contests\n",
      "====================\n",
      "This is my last straw. I'm not going to be a cog in the machine. I'm going to be a man who's going to stand up for what's right.\"\n",
      "\n",
      "In response to Trump's comments, the president's campaign released a statement, saying: \"Mitt Romney was the last Republican governor of Massachusetts to sign into law the 'No Taxpayer Funding for Abortion Act' which is a blatantly unconstitutional and unconstitutional attempt to limit the rights of women. He is the only Republican in the entire history of\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              model_name=model_name,\n",
    "              prefix=\"This is my last straw\",\n",
    "              length=100,\n",
    "              temperature=0.7,\n",
    "              top_p=0.9,\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities\n",
    "- try varying the prefix. \n",
    "  - what length of prefix works best with the given model? \n",
    "  - how does the choice of prefix change the format/form of the output.\n",
    "- try varying the temperature.\n",
    "- try loading the different sized models (124M, 355M, 774M, 1558M) and generate text without changing the other parameters. \n",
    "  - Do you notice any qualitative differences in the output? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fine-Tuning GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 02:45:45.663212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"355M\" # same model as selected above\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# check if sess exists (e.g. if we ran section 1 above)\n",
    "var_exists = 'sess' in locals() or 'sess' in globals()\n",
    "\n",
    "if not var_exists:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeeSKtNWUedE"
   },
   "source": [
    "## Upload a text file\n",
    "For this, we will use a text file you provide to finetune (continue training) GPT-2. You can use any plain text (.txt) file. \n",
    "\n",
    "Simply drag and dropy our text file into the file browser at left. \n",
    "\n",
    "Once you have uploaded your file, update the file name in the cell below, then run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6OFnPCLADfll"
   },
   "outputs": [],
   "source": [
    "file_name = \"conglomerateSpeeches.rtf\" # your file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Run the finetuning\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every `save_every` steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them. If your input text is smaller, training might proceed more quickly.\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
    "\n",
    "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "* **`sample_every`**: Number of steps to print example output\n",
    "* **`print_every`**: Number of steps to print training progress.\n",
    "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For larger models, the recommended finetune() parameters are:\n",
      "\tuse_memory_saving_gradients = True\n",
      "\tonly_train_transformer_layers = True\n",
      "\taccumulate_gradients = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 02:47:22.857829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 66625 tokens\n",
      "Training...\n",
      "[10 | 25.78] loss=2.92 avg=2.92\n",
      "[20 | 45.63] loss=2.66 avg=2.79\n",
      "[30 | 65.64] loss=2.67 avg=2.75\n",
      "[40 | 85.53] loss=3.05 avg=2.82\n",
      "[50 | 105.45] loss=2.56 avg=2.77\n",
      "[60 | 125.34] loss=2.72 avg=2.76\n",
      "[70 | 145.23] loss=2.80 avg=2.77\n",
      "[80 | 165.15] loss=2.86 avg=2.78\n",
      "[90 | 185.06] loss=1.96 avg=2.68\n",
      "[100 | 204.94] loss=2.41 avg=2.66\n",
      "======== SAMPLE 1 ========\n",
      " keep your hands to yourself and keep a clear mind. In this you will survive. The devil has many enemies and one of them is pride. You will be an inspiration to me and to every one who has his eyes open. So the devil is very jealous of me and he is trying very hard to undermine mine. He is trying to get me from my perch. But I will not be taken down as he can see. I am there as a rock and will never give in as long as there are human beings on earth. And I ask you, how are you the devil to be betrayed? The devil does not trust men. The devil says to me, \"How has the devil got possession of you? How have you dared to open your mouth and the devil can speak to you? You are but a woman. But he who shall say to you, 'My son, what is the cause of your going astray?' is like a little child who is placed in a large well. It does not work, for the well is full of water. How then can you tell where the well is? You ask and you receive. But they who say to you, \"I have faith,\" do not know what they mean, for what they say is impossible. How then can they say, \"I have faith,\" when they know you do not have faith? For you know that the testimony is flesh and blood, and that nothing can be more impenetrable than human reason. It is man that says, \"Yes, but what is the reason for my believing this or that?\" You then who are the true sons and daughters of God and the true sons and daughters of man, if you have faith in one another, if you say to the falconer, \"I want to know,\" and the falconer says to you, \"Go to the city and tell all the people of that city all you know,\" and if you say to the falconer, \"I do not know, I do not even know what I want to know,\" he will say to you, \"You see, my friend, I do not know; I am an unbeliever.\" (That is the way the devil can betray a woman who does not dare to go astray.) He says to you, \"It would be a shame to keep you from what I want. There is nothing to be afraid of.\" If you say, \"I know you don't know, I will tell you about it,\" he will say to you, \"Go and tell the world what you know.\" It is this, \"I will go to the end of the earth and preach my gospel to you.\" You see, if you tell a lie big enough, eventually the truth will come out. So it would be a great shame if all the human leaders on earth listened to the voice of reason. They would do themselves great harm. They would be the best teachers in the world if they were all to remain idle. And who are these wise and learned men? And so on and on. \"The Bible says,\" (The devil says, \"Do as the wise men do and you will lose your way and you will go astray,\" etc.) \"Go into all the world and preach the good news to the Gentiles, the whole earth, as I lay down my life for you.\" And to go into the world (The devil said, \"Go into all the world and preach every word with a loud voice until I come on the earth to persecute you and persecute those who are near you with fire and sword and to destroy the saints and all who bless you and keep you from doing evil,\" etc. And so on and so on), and they are the ones who will lose their way. Those wise and learned men know that they must preach the truth. They must not allow anyone else to preach. Then I ask everyone, what would you do if you were an ordinary human being? You would do as I say and you would lose your way. Now, you are the wise men. Why do you do what I do? It is because I care for you. My life depends upon it. How could I lose my life doing what you are doing? Is it not a great pity, because I am so greatly concerned for you, and yet you are so unhappy, and I am the one who is most interested in you? It can only be through you that they are unhappy, for I spend all my energy on their behalf. But suppose that the devil, or someone of the devil, were to appear before you and say, \"This is my Will,\" and you did as he said, and you did what was expected of you from him when you were ordered, would that be a good thing for you? It will be for you an evil thing. And so you should be careful, for you do not know if you do as is right. If you do not give even the smallest thought to whether that is right or not, it\n",
      "\n",
      "[110 | 242.47] loss=1.95 avg=2.59\n",
      "[120 | 262.45] loss=2.42 avg=2.57\n",
      "[130 | 282.43] loss=2.66 avg=2.58\n",
      "[140 | 302.41] loss=2.50 avg=2.57\n",
      "[150 | 322.40] loss=2.45 avg=2.57\n",
      "[160 | 342.41] loss=1.93 avg=2.52\n",
      "[170 | 362.39] loss=2.03 avg=2.49\n",
      "[180 | 382.40] loss=2.29 avg=2.48\n",
      "[190 | 402.38] loss=1.86 avg=2.44\n",
      "[200 | 422.36] loss=2.04 avg=2.42\n",
      "Saving checkpoint/run1/model-200\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=200,\n",
    "              restore_from='fresh', # change to 'latest' to resume\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              learning_rate=1e-5,\n",
    "              sample_every=100,\n",
    "              save_every=200\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXSuTNERaw6K"
   },
   "source": [
    "## Notes on finetuning\n",
    "\n",
    "Keep an eye on the loss, and how quickly it is dropping. A too-rapid drop in loss could be a sign of overfitting, and a learning rate (lr) that is too high. \n",
    "\n",
    "After the model is trained, you can download the checkpoint folder to save your work. Training checkpoints are saved to `checkpoint/run1` (or whatever you chose for the run name above).\n",
    "\n",
    "You can compress it to a rar file and download that. Ask the instructor how.\n",
    "\n",
    "You're done! Feel free to go to the Generate Text From The Trained Model section to generate text based on your retrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 02:56:34.402731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"355M\" # same model as selected above\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# check if sess exists (e.g. if we ran section 1 above)\n",
    "var_exists = 'sess' in locals() or 'sess' in globals()\n",
    "\n",
    "if not var_exists:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune some more, run the following. Be sure to increase the number of steps (if it was `500` before, change to `1000` to train for 500 more. the number is cumulative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For larger models, the recommended finetune() parameters are:\n",
      "\tuse_memory_saving_gradients = True\n",
      "\tonly_train_transformer_layers = True\n",
      "\taccumulate_gradients = 1\n",
      "\n",
      "Loading checkpoint checkpoint/run1/model-200\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-200\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 66625 tokens\n",
      "Training...\n",
      "Saving checkpoint/run1/model-200\n",
      "======== SAMPLE 1 ========\n",
      " \\1\\b0 \\cf2\\pard\\tre\\pardar\\pardar\\sa'\\cf3\\cf8\\cf92\\c0020\\cfa0\n",
      "\\cfa0 (4)\n",
      "\\cf9 (5)\n",
      "\\da0 It has no connection whatsoever with the question of nonviolence, to my mind, or to the mind of the common man. And the idea that we should say: 'This is wrong, but let it be, it is wrong, it is wrong,' that is contrary to reason.\\\n",
      "The idea that we should say: 'This is wrong, but we can't do anything about it, we can't even change this little bit, so let it be, we can't do anything about it for the time being and, if this means change, then change it, or else stop fighting; otherwise, fight more and more and more, and there's no hope for India' is also an idea that I do not support.\\\n",
      "I have not said that we must accept the verdict of the world world-wide boycott. The boycott was designed so that, if India carried out a course of action that was in accordance with what was called the Madras Principles, that would lead to a change in the policy of India, the world would recognise it.\\\n",
      "Even here I think we can't go beyond this. We need to consider the option of continuing the boycott. I have always opposed the attempt to wage a 'just war', a 'just negotiation'. Even if, say, we were to take a decision to send our soldiers to fight in the Sudan, to go to Egypt, for instance, we should not take a decision not to go to the UN in order to try to persuade it to recognise the call of the boycott, for the same reason we should not take a decision to go to the UN in order to seek a loan, a guarantee from your finance agency, if we are to be able to go, if we are to seek a loan from the international financial organisation in the future. We cannot engage in a struggle of negotiation as that is an engagement in a struggle. If any man thinks that it is acceptable to give to the world a promise that he will not use force, that he will not use violence, he, of course, betrays a false consciousness. That is why I have always opposed a strategy of negotiation. I have always opposed it in several other ways.\\\n",
      "Let the fact that I have always opposed it, however, does not mean that it is right. And the fact that I have said: 'If you think that the world is ready to make a promise, a promise, to let a man go to the front in order to compel him to make a certain economic commitment, then you also should not go and make a 'political' commitment to honour your word. You should not settle for a promise that does not stand, a promise that does not fulfil its promise if you do not intend to honour it, and a promise that you cannot honour if you intend to honour it,' does not make that promise not a real promise. It is an honest promise made after all. It is a promise that can be taken very seriously. And so does the truth of the statement that I made before the UN, when I said : 'I have come with the conviction that, if India becomes a great nation, the world can no longer afford to leave India alone. I want India to see clearly that what I propose today, or what you propose today, the world must come to India and recognise as a matter of course, that India is ready to fulfil the commitments it has made made for the country - a nation that has given away more than half its birth-place, let us say, in a series of glorious conquests - that the world is ready to recognise the promise that I have made to India today.\\\n",
      "\\\n",
      "\\\n",
      "Let me now read a quotation from the same speaker. He said : 'The English have come in search of gold. They have gone up to the rocks, they have tried to find it in the rocks, they have tried to reach the mountains, and they have no more. The rocks they have sought for in India. In India the rocks have brought them gold....\\ \\\n",
      "This has always been our attitude, and will continue to be so. This is our attitude now because the English have gone to the mountains, because the English have gone up to the rocks, because the English have gone up to the heights, and in order to attain a height which they now lack, the people of India had to search for it, and found it within their own villages which in the days when the people were villages they were free from danger.\\ \\ \\\n",
      "What I have said, in the last resort, is my own view. That too I put in the scale of time. I said a moment ago: 'If God so wills, I shall have passed over a millstone in my rope\n",
      "\n",
      "[210 | 42.78] loss=1.81 avg=1.81\n",
      "[220 | 62.60] loss=1.52 avg=1.66\n",
      "[230 | 82.56] loss=1.70 avg=1.68\n",
      "[240 | 102.57] loss=1.63 avg=1.67\n",
      "[250 | 122.55] loss=1.76 avg=1.68\n",
      "[260 | 142.52] loss=1.53 avg=1.66\n",
      "[270 | 162.49] loss=2.11 avg=1.72\n",
      "[280 | 182.48] loss=1.55 avg=1.70\n",
      "[290 | 202.46] loss=1.74 avg=1.71\n",
      "[300 | 222.43] loss=1.23 avg=1.66\n",
      "Saving checkpoint/run1/model-300\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages/tensorflow/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 1 ========\n",
      "\\\\\n",
      "\\pard\\pardeftab720\\sa240\\partightenfactor0\n",
      "\\cf3 \\cb8 One more thing.\\\n",
      "Our position at this juncture has been made evident to all. It is beyond dispute that the situation confronting Germany in the last ten days demands a more aggressive European course. I repeat - our position has become absolutely clear. The time for playing dead is long past.\\\n",
      "The entire international community is now on our side. Not a German soldier has gone to fight a battle within the frontiers of Germany. There were some isolated incidents, undoubtedly. But for the determination, solidarity and solidarity of the whole international community Germany would not have been able to hold out to itself the freedom which rests at the core of a European community.\\\n",
      "Through your conduct in the West also, we have clearly seen that you do not intend to settle for merely subaltern behaviour. You intend to play a leading part in brokering the solution of the Jewish question.\\\n",
      "This resolve was instilled into the very very DNA of my Party. I have often thought that our present standing in the world economy is a legacy of your influence. The world market has given way to the world market. This has contributed to the crisis of German prosperity. It is therefore with a certain measure of deep regret that I come to say that the German people has voted for a European Community in order to secure for itself the markets and security of a strong international position. This position has through the Movement of the German people, uniting behind it, secured this accession of greatest German prosperity to the last years of the nineteenth century.\\\n",
      "All of this has been achieved within the framework of the democratic peace. But, as we have seen, the settlement of the Jewish question can only be settled through direct Jewish action. The German people has always considered the solution of the Jewish question to rest entirely with the Nation-State. This settlement has nothing to do with the conception of the Jews as a homogeneous collectivity. For the German people the Jewish question is no more than the problem of who shall decide the future for his people in the final settlement of her problem of existence and existence in the world. That is what has compelled all Jewish organisations to continually appeal for the establishment of a Jewish national home in Palestine-a homeland for the Jewish people. That is why we have always insisted that the issue of the Jewish problem should be decided solely between the Government of Palestine and the people of Israel, and solely in accordance with the spirit of equality under the law. There can be no Palestinian unity if the nation in question must make its decision after consulting with its leaders in Jerusalem, and following the usual procedure.\\\n",
      "But our deliberations and the deliberations of our peoples in the past have not led us to a single vacillation on the Jewish question. They have repeatedly insisted on the absolute indissanguinity of the two peoples. Their adherence to this indissanguinity has, therefore, never wavered one iota.\\\n",
      "The problem before us now is so grave that it demands an attitude beyond the vacillation of the past. The Jewish problem demands a correct attitude in all its dimensions - the Arab problem, the Palestinian problem, the economic problem and the sensitive situation created by them - the general Palestinian question, and the specific demands for equality before the law - this general problem and these specific demands demand a joint effort from all members of the Palestinian national movement.\\\n",
      "It is we alone amongst our peoples who constitute the general Palestinian movement, who constitute the mass of the people consciously committed to carrying out the Declaration entitled Palestine.\\\n",
      "With the creation of the State of Israel our tasks also look brightening ahead. For us a Palestinian state is a goal we have been striving for the last 60 years, a goal which would make possible not only to our people the realization of our national goal but also to a democratic one. But there is a fourth dimension that we must guard against - there is the danger that our project of democracy may, at some future stage, be totally out of date and insufficiently progressive in character.\\\n",
      "In this light it must be clearly seen that the creation of a Palestinian state is incompatible with equality before the law - with the right of the people as a whole to their own existence. What is at stake today in the creation of a Palestinian state is today already nothing short of the creation of Israel. For in so far as a people is established on the land it is its right and duty their right and their duty to inherit. A people is established on the land to ensure its continued existence, to ensure its existence as a homeland for its people.\\\n",
      "The creation of such a state threatens the possibility of achieving this end. For the creation of a Jewish State will mean the establishment also of an Israeli State. The creation of such a state carries also for its supporters the danger of weakening the already weakening hand of the Palestinians towards establishing a democratic and equal partnership with the entire Arab and Muslim world.\\\n",
      "In short, the creation of\n",
      "\n",
      "[310 | 260.70] loss=1.59 avg=1.65\n",
      "[320 | 280.68] loss=1.52 avg=1.64\n",
      "[330 | 300.65] loss=1.31 avg=1.61\n",
      "[340 | 320.62] loss=1.21 avg=1.58\n",
      "[350 | 340.60] loss=1.18 avg=1.55\n",
      "[360 | 360.56] loss=0.82 avg=1.50\n",
      "[370 | 380.56] loss=1.20 avg=1.48\n",
      "[380 | 400.54] loss=0.96 avg=1.45\n",
      "[390 | 420.50] loss=0.93 avg=1.42\n",
      "[400 | 440.48] loss=0.73 avg=1.38\n",
      "Saving checkpoint/run1/model-400\n",
      "======== SAMPLE 1 ========\n",
      "1\\r\n",
      "\\r\n",
      "\\r\n",
      "\\r\n",
      "\n",
      "\n",
      "[HORN! HALFTIME! SURROUNDING THE HOUSE]\n",
      "\n",
      "\n",
      "O friends! [HORN! HALFTIME! SURROUNDING THE HOUSE] [HORN!] [SURROUNDING THE HOUSE!][HORN! HALFTIME!]\\\n",
      "\\r\n",
      "\n",
      "O friends!\\\n",
      "\n",
      "[HORN! HALFTIME! SURROUNDING THE HOUSE] [HORN! HALFTIME!] [HORN!]\\r\n",
      "\n",
      "[CHORUS\\r\n",
      "\n",
      "BAPTIST CHORUS]\\r\n",
      "\n",
      "\n",
      "Writer(s): D. MICHAEL KELLY, RONALD WALTERS, KEITH EARLSTEIN, DANIEL W. GOULD, TONY A. JOHNSON, ALAN C. HOWARD, HOWARD F. PARSONS, ARNOLD BROCK, DONALD J. MICHAEL, ANDY NABERMAN, ANDY KELLY, BILL SNYDER, GEORGE RUBIO, KEVIN WOLFMAN, GREG COATES, GEOFFREY CUMMINGS, GEOFF ROBERTSON, HOWARD J DANIELS, JERRY DEAN, JIM DEAN, JOHN DEAN, KEVIN DEPT SCHOLAR, MARK E SNYDER, MARLA VERMINE, MICHAEL VAN WALLEE, MARC DEAN, MARLA VERMUNE, MICHAEL WEBSTER, NAOMI BEN-NISSER, NANCY E. SCHWEIZER, PARENTHOOD\\r\n",
      "\n",
      "\\\n",
      "\n",
      "\\r\n",
      "\n",
      "February 14, 2008\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "ENDNOTES\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "On Sunday February 7, as thousands of Palestinians and their supporters came together in Chicago to mark the fourth anniversary of the Arab Spring uprisings, the U.S. government and its media allies in the Israeli and U.K. press were at pains to whitewash these uprisings and to ignore the fact that they were being bankrolled and co-opted by the U.S. military-industrial complex.\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "This fact has been hidden from the American people by the mass media coverage of the Arab uprisings, which in turn has been controlled and regulated by the U.S. government. The largest daily newspapers in the United States, New York, Los Angeles, and Chicago, predominantly remain owned by the Jewish community. The leading newspapers in Britain, The Guardian, Sunday Mirror, and Sunday Mail, are mostly owned by the Anglo-Saxon community. The Sunday Telegraph in inner London is also overwhelmingly Jewish. But with regard to the rest of the United States, there are smaller daily papers owned by the various religious communities, as follows: African Methodist Episcopal\\u00a0 Christian\\u00a0 Jewish\\u00a0 Hindu, Muslim, or other minority\\u00a0 group. In addition, there are about 20 weekly papers in the United States, mostly owned by small papers or no longer in business. All of these were controlled by the working class during the 1920s and '30s and '40s.\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "And while the American people was being brainwashed into supporting the U.S. military-industrial complex carried out by the Democratic and Republican administrations of the last thirty years, including the War in Iraq, the largest U.S. newspaper, The New York Times, also controlled by Jewish owned firms, carried out its job of paying no attention to the daily Arab uprisings.\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "This fact was further underscored by a series of articles in The New York Times over the last month, including an article by the noted Arabist and political analyst, Abdulslah Kaya; an article by the award winning journalist, Saba Saad; an article by the leading peace activist, Marion Hammer; an article by the leading Arab human rights lawyer, Ahmed Jalloh; and articles by writers such as Chris Hedges, Noam Chomsky, Noam Gabriel, Noam Gabriel Jr., Justus Ranke, Noam Chomsky, Noam Iyad and others. This veritable army of international observers was there to record the Arab uprisings and report back to the readers of the New York Times.\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "The readers of The New York Times were treated to an in-depth study of these Arab uprisings, based on primary sources and previously unrivaled access to leading activists, activists, academics, and journalists in the Arab world.\\r\n",
      "\n",
      "\\r\n",
      "\n",
      "As a result of this groundbreaking study The New York Times carried a variety of important articles and pieces about the Arab uprisings. Among these was an article by myself entitled\\u\n",
      "\n",
      "[410 | 478.68] loss=0.79 avg=1.35\n",
      "[420 | 498.64] loss=0.68 avg=1.32\n",
      "[430 | 518.60] loss=0.63 avg=1.29\n",
      "[440 | 538.56] loss=0.82 avg=1.26\n",
      "[450 | 558.53] loss=0.66 avg=1.24\n",
      "[460 | 578.40] loss=0.53 avg=1.21\n",
      "[470 | 598.22] loss=0.51 avg=1.18\n",
      "[480 | 618.04] loss=0.49 avg=1.15\n",
      "[490 | 637.85] loss=0.31 avg=1.12\n",
      "[500 | 657.66] loss=0.53 avg=1.09\n",
      "Saving checkpoint/run1/model-500\n",
      "======== SAMPLE 1 ========\n",
      " but now in the absence of a better method we have lost the right and the means of ensuring that right. [. . .] The Congress did not say no, it said how? We shall find out after the elections. For the Congress has done nothing whatsoever to ensure the vote secrecy so that the worst cannot happen and that nobody else can commit the same sin. We shall find out in the course of the elections how little the Congress has done, and how much it has done. You may laugh, but you cannot take away laughse as I have done.\\\n",
      "[Speech at the 17th congress (1905))] There was a time when Congressmen and lawyers used to meet secretly and come to a decision. They would go ahead and give the law the sanction it deserved. But in the last analysis it was the people who came to the Congress hall and made the determination. If Congressmen believed in the democracy they were sending the law astray. And if Congressmen did not believe in the democracy, how could they believe in the victory of democracy over disunity created by disunity? In the last analysis, we are a people of laws and a people of disunity of individuals. There can be no compromise which does not at the very least recognise the fundamental unity of the oppressed and the oppressor peoples. There can be no accommodation which does not at the very least makes a renunciation of one's own fundamental rights as the last resort of a people which believes that only by renouncing these rights can it possibly reach a peaceful settlement. That is the basic unity between the workers and the masses of the people and needs to be maintained.\\\n",
      "What, then, is the way out for the representatives of disunity a means of uniting the people and of establishing upon a basis of agreement on the dictatorship of the people? If we take these questions very seriously, then a fair plan is below. The Congress must agree in the following areas: (i) To amend the Constitution, in order to bring about the goal of producing an Accord signed by the various Napoleonic dynasties, peoples with small minorities in different branches of the Armed Forces, etc. (Removing all titles to evade Parliament's restrictions). (2) To propose Bills for Conference, in order to obtain assent thereof. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (3) To propose New Measures, in order to avert an Enclave. In Either Case, C.I.F. Consensus is required before the Congress can commence any Action. (4) To propose Bills of Minute, if the situation warrants it. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (5) To urge that the people should be given the right to Change their Dictatorship propose for ratification by a smaller Number. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (6) To urge that immediate Reorganisation of the French Revolution be ordered into a Program and a Programme. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (7) To urge the establishment of a Permanent Committee of Non-Partisans to consider all Budgets, New Measures, Resolutions and All Ways of Moving Forward. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (8) To urge that a Programme and a Minute should be put together for the Executive Branch, with a Compromise Draft for the Legislative Branch to consider at once. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (9) To urge that a full Report and Criticism of all that has taken place in the Occupied Countries, be made immediately available to the Public. In either Case, C.I.F. Consensus is required before the Congress can commence any Action. (10) To urge immediately for complete Mandate the Establishment of a French Army in Normandy and the Loire-Bayonne-Thesous, and at the Head of a French Air Force in order to repel any American Attempt to Use its Aids-A French Vaccine and a French Injector. In either Case, C.I.F. Consensus is required before the Congress can commence any Action.\\\n",
      "[Pause] Madam President, I approach for the first time, in the name of all the oppressed and exploited on this soil, who hitherto walked in silence before the Akalis and theTatars, and hitherto vacillated between the Terror and theBolshevik Extremes, and I approach in the name of the dispossessed masses of this country and theearthquake-stricken peoples of the world, and ask you to stand with the masses of the continent against this monstrous act of terrorism and this new\n",
      "\n",
      "[510 | 695.08] loss=0.32 avg=1.06\n",
      "[520 | 715.03] loss=0.32 avg=1.04\n",
      "[530 | 735.00] loss=0.30 avg=1.01\n",
      "[540 | 754.98] loss=0.23 avg=0.98\n",
      "[550 | 774.94] loss=0.27 avg=0.96\n",
      "[560 | 794.90] loss=0.28 avg=0.94\n",
      "[570 | 814.87] loss=0.29 avg=0.92\n",
      "[580 | 834.83] loss=0.27 avg=0.90\n",
      "[590 | 854.81] loss=0.36 avg=0.88\n",
      "[600 | 874.77] loss=0.22 avg=0.86\n",
      "Saving checkpoint/run1/model-600\n",
      "======== SAMPLE 1 ========\n",
      " and thus the state can then be described by various terms, the first of which is 'supra-state'. This is the attitude of the president and his close associates towards the Congress government. They see it for what it is: an occupying power in India who occupies the capital and who keeps the people under its strict thumb.\\\n",
      "The attitude of the Congress to this occupying power is, in a word, one of fear. It is afraid lest the Congress should be able to the do what it could not do as at the start of the war and what at first it thought it ought: to make war- weariness set in amongst the Arabs and Indians, and thus to gain for itself an absolute domination of India. Congress feels that it must keep the people so worn out that it will for ever remain silent about the Tamils, and the French massacres, and the English hangings, and about all the big things that Congress can't do a thing about. Congress therefore fears lest the government should become so tyrannical as to compel the people to do things it couldn't possibly consider tyrannical. The other term in the constitution includes our right to peaceful assembly. To secure this right, the Congress has drawn up a list of 14 demands upon which the fourth Schedule of Hindu Dharma is founded. These demands include theutmost right to education for all, including an end to the violence and abuse to women and children,an end to the crop denial and other forms of deprivation of this right, an end to caste discrimination,an end to discrimination in employment and in all other areas,and an end to socially constructed mentalities and racial groups. The Hindu religious community as a whole The Hindu community in India is among the largest in the country. Our members inhabit predominantly the agriculturational strata of the country. They make cotton, tobacco, sugar beets, beans, sugar beets, rice, beans, sugar beets. They make of these riches the wealth to makeIndia one great nation of farmers. Every Hindu farmer produces one less and thereby loses one less worker's right. Every Hindu is thus empowered. It affords him the highest ideals of social justice and justice of mind. Every Hindu who happens to settle in a State like Gujarat, Madhya Pradesh, Madhya USA, where the Constitution has been violated to the bursting, will be of the greatest assistance to him. He will be of the opinion that no State is possible in which to find constitutional equilibrium. Such persons as are destined to succeed him will have suffered enough ruin to be ready for any change. State terrorism prevails everywhere. Social engineering has become the order of the day. Many of the finest works of civilization in Europe have been destroyed, and even more dearly placed lives. In India, Social engineering has become the order of the day. Many of the finest works of civilization in Europe the last century and a quarter to have been raised and are still standing suffered ruin. In other words, great and small structures, secular and religious, monumental and secular in character have been demolished and if social engineering projects had not come into vogue in the last fifty or sixty years, we may perhaps be told that the world is teeming of waste, that the land is already waist deep inible and lifeless, that urbanization will cause death to overburden the masses, suicide among the masses, and will ultimately lead to the rise of some other power than ourselves. This is not the hope we wish to project. We wish to make one thing plain: This is not the hope of a humanistic people on earth to which I have belonged my whole life. I had lost in the 1960's my faith in inspiration, and feeling, in the spiritual side of things. I lost in another respect, as well. I lost in the third respect - justice. Today I mean Prabhat Jahangir who was martyred yesterday evening in Amritsar, and Vishnu was born yesterday. If I were alive in those days, today I would ask myself, what is the greatest harm that could have been done to justice, if the nation and the world world and the immortal soul of India and the world had been harmed? Had the English, French, Italians, Poles, Soviets, Englishmen, Frenchmen, Italiansmen, Frenchmenossletakesoairaynow? Had the English, Frenchmen, Italians, Russiansoakenedmen? No;theyoartedakenanceago. Yes, theyoartedakenancegoneaightnow. . . But if I were alive in those days, and I saw that the English, Frenchmen, Italians, Russians, had done their utmost to destroy India and the world by atheistic communism, Nismegeneutrality,I wonder if I should no longer do myself justice if I said that the greater harm that could have been done, the urdest injury that could have been donetothem, wasdone, the vilest hurt was done, and the world and the urdest urdity hasakenhold urd\n",
      "\n",
      "[610 | 912.53] loss=0.27 avg=0.84\n",
      "[620 | 932.51] loss=0.17 avg=0.82\n",
      "[630 | 952.48] loss=0.26 avg=0.81\n",
      "[640 | 972.44] loss=0.22 avg=0.79\n",
      "[650 | 992.40] loss=0.19 avg=0.77\n",
      "[660 | 1012.36] loss=0.20 avg=0.76\n",
      "[670 | 1032.32] loss=0.21 avg=0.74\n",
      "[680 | 1052.28] loss=0.16 avg=0.73\n",
      "[690 | 1072.25] loss=0.21 avg=0.72\n",
      "[700 | 1092.22] loss=0.21 avg=0.70\n",
      "Saving checkpoint/run1/model-700\n",
      "======== SAMPLE 1 ========\n",
      " mistake. And we have a responsibility to meet that responsibility.\\\n",
      "We should follow in the footsteps of our friends and allies in South Africa and other places in the world and end apartheid.\\\n",
      "I do not believe that apartheid can be abolished overnight. But I do believe that we must end severe apartheid today.\\\n",
      "We must end the apartheid wall that surrounds our people in South Africa. We must end the economic apartheid that oppresses our people. And we must end the social apartheid that oppresses the lives of our people.\\\n",
      "We must end racism in all of its forms, economic racism, political racism, and cultural racism.\\\n",
      "Since our people's heroic defence of the liberation of our people from the Yankees of 1975 to the present, the Natal led by the late Ian Smith, and our people's leading forces in the Cape, Durham, and the Indian Negev, there has been an incredible march towards that glorious goal.\\\n",
      "But despite all that our people has gone through, the wall that surrounds our people still prevents the township of Johannesburg from being a city of South Africa. We must overcome this wall if we are to rid our country of the racism that still binds us together as one.\\\n",
      "The township of Johannesburg is a city within a city. It contains within its borders the sons and daughters of the many Africans who have lived and worked on the fringes of Apartheid for more than seventeen years. As South Africa we are guided by the democratic values that this city exemplifies. Although not located within the hubbub of international commerce, Johannesburg and its surrounds are a principal port and trading hub for the broader Kingdom of South Africa.\\\n",
      "I am sure you are well aware that the general prosperity and well being of the larger Kingdom of South Africa hinge upon the energy and growth of Johannesburg and the surrounding townships. Although I hope that you are also aware that the prosperity and growth of Johannesburg depends in no way upon the maintenance of the oppressive apartheid wall separating the township and the larger Kingdom of South Africa.\\\n",
      "It is a fact of life in Johannesburg, and a fact of experience in the wider Kingdom of South Africa, that the petroleum wealth of the oil-rich Outer African Province can be exploited only if the Kingdom can be enriched from the within out. Exporting our economy, talent, and energies to arap-el-HindORE is killing our economy, draining our talent, and swamping our communities. Pollution from the burning of fossil fuels in the economy and the transport of these resources threatens to contaminate the water sources and desalination facilities that serve our people.\\\n",
      "It is both fact and fact that as a result of all of this pollution, as many as four million South Africans suffer from stunting and less than one-third of one percent of boys are born with full physical strength. As a result of stunting and undernutrition, as many as three million South Africans suffer from underweight and more than two-thirds of children under five are stunted. As many as two and a quarter million South Africans suffer from anemia. As many as two and a quarter million South Africans suffer from vascular diseases, mainly due to poor diet. As many as two and a quarter million South Africans suffer from handicaps, mainly due to handicap walking.\\\n",
      "As you can guess from the above, I find it impossible to forgo the right to food and the right to sufficient food even if it means malnutrition and the handicaps mentioned before. I refuse to forgo the right to health care and to the right to the right to adequate health care. But there cannot be leaving any one or other of these untouched. If one or the other of these does not arrive sooner or later, then we will all be in for a big trouble.\\\n",
      "In order to fulfil these responsibilities as Prime Minister, I was\\\n",
      "president of our county from 1995 to 2001. During that time we witnessed a dramatic improvement in the lives of all South Africans. The proportion of people living in absolute poverty fell to less than ten percent. The proportion of people living in absolute poverty as a percentage of the national total fell to less than five percent. During that period we witnessed an unprecedented cultural revolution taking place all over our country. Thousands of new cultural centres have sprung up throughout our country. Thousands of old cultural centres have sprung up throughout our country. As you can see, things are looking up for all of us. We are living in a golden age of learning and cultural revolution is having an unprecedented cultural and economic impact.\\\n",
      "In the current parliamentary session, which commenced today, we had two ANC members elected from our province and one from our country west of the KwaZulu-Natal divide. Both of those were ANC members. They will now be joining forces with me to take our fight for liberation all the way to the top!\\\n",
      "In the words of our glorious Black National Party, this is our victory lap!\\\n",
      "We celebrate with our heroes our liberation heroes like\n",
      "\n",
      "[710 | 1130.05] loss=0.22 avg=0.69\n",
      "[720 | 1150.01] loss=0.17 avg=0.68\n",
      "[730 | 1169.90] loss=0.20 avg=0.67\n",
      "[740 | 1189.73] loss=0.17 avg=0.65\n",
      "[750 | 1209.56] loss=0.17 avg=0.64\n",
      "[760 | 1229.37] loss=0.14 avg=0.63\n",
      "[770 | 1249.22] loss=0.18 avg=0.62\n",
      "[780 | 1269.14] loss=0.19 avg=0.61\n",
      "[790 | 1289.10] loss=0.16 avg=0.60\n",
      "[800 | 1309.07] loss=0.14 avg=0.59\n",
      "Saving checkpoint/run1/model-800\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=600,\n",
    "              restore_from='latest', # change to 'latest' to resume\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              learning_rate=1e-5,\n",
    "              sample_every=100,\n",
    "              save_every=100\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "# 3. Generate Text From The Finetuned Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "82574eaa-d39a-4665-b611-e5172848da57"
   },
   "outputs": [],
   "source": [
    "# gpt2.generate(sess, run_name='run1') # no prefix, unconditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With me I have the roadmap for the evolution of humanity. In this, we are in agreement with all those who cherish individual freedom. But we do not agree on a road map.\\\n",
      "The 'roadmap' is the basis for action. If we want to go on moving humanity forward on the path of freedom, we must lay down our weapons and find a common strategy to utilize their power in the direction we all want to go. This will give us the power to effect what we all realise must be done: the civilization of apartheid has to be totally and totally destroyed. The path along which we are marching must not be one of negation but of collaboration. We must-we must have at our side the greatest hunger strike, the zealous struggle for food and medicine and clean drinking water that humanity has ever seen. If we fail, the future is not freedom, but satiation of that very hunger strike and of our great revulsion against the world that is filled with violence and greed. [Applause]\\\n",
      "\\\n",
      "The British colonial rulers kept us divided, our people apart. When the British took over our freedom was lost. When our countrymen returned to our land, they found us divided up our people between those who loved them and those who could not live without them. The former were made to feel as if second-class citizens, while the latter were made to feel as though we were their enemies. Our freedom was brutally crushed, and our people plunged into confusion. Through violence and desperation, we were able to recover some order, but the damage was complete. The memory of the horror that was done to our country lives in our veins, and we remember it every time the British want to make a quick gain by dividing us up again.\\\n",
      "A strong, confident and industrious Zimbabwe is the heritage of all our people. Their children and grandchildren will too be heirs of this proud heritage. Multitude of our people have migrated to the west coast of Africa in search of land. The result has been a massive emigration of landless workers. As a result, the number of people with no land to their names has grown to a point where there is nothing for new formation of land divisions.\\\n",
      "Scarcely six months ago it would have been reasonable for us to have harboured any resentment towards the Zimbabweans. But things have changed dramatically since the early nineties. Some of us hold political offices in Zimbabwe. We are even invited to travel to Zimbabwe to represent our country in the United Nations. It must be surely a sad day for Zimbabwe if some of our people choose to regard us with any contempt. Yet, we have grown weary of the inflamed hatred that has grown up between the Zimbabwean people and ourselves. We the citizens of Zimbabwe have faced rejection at the hands of the British, the Zimbabweans have faced rejection at the hands of the colonial rulers, the foreign visitors have faced rejection at the hands of these successive rejection, and yet somehow, somehow, somehow the hostility between the two races, Zimbabweans and Zimbabweans, remained alive.\\\n",
      "It must be surely a sad day for us if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically since the mid-nineties, when the situation was different. It must be surely a sad day if some of our people, because we are Zimbabweans, should regard us with any contempt. But it has changed dramatically in the last twenty-five years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty-five years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty years. It must be surely a sad day, if some of our people, because we are foreigners, should regard us with any contempt. But it has changed dramatically in the last twenty years. It must be swiftly and effectually! - the President made the point - it was not a new point - it was not a new reality - it was that the British people, through us, through our leaders, repeatedly and deliberately raised the flag of apartheid, did more harm to our race than the entire bombing and looting of South Africa had done to the white race.\\\n",
      "\\\n",
      "The President made the point - it was not a new\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1', prefix=\"With me I have the roadmap for the evolution of humanity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4-PqF0Fl7R"
   },
   "source": [
    "## Notes\n",
    "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
    "\n",
    "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
    "\n",
    "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
    "\n",
    "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
    "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DKMc0fiej4N",
    "outputId": "490a4648-d973-4675-cf9a-7a48c16fd736"
   },
   "outputs": [],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=250,\n",
    "              temperature=0.7,\n",
    "              prefix=\"LORD\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjEN2Tafhl2"
   },
   "source": [
    "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
    "\n",
    "You can rerun the cells as many times as you want for even more generated texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa6p6arifSL0"
   },
   "outputs": [],
   "source": [
    "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
    "\n",
    "gpt2.generate_to_file(sess,\n",
    "                      destination_path=gen_file,\n",
    "                      length=500,\n",
    "                      temperature=0.7,\n",
    "                      nsamples=100,\n",
    "                      batch_size=20\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-LRex8lfv1g"
   },
   "source": [
    "Download the file by hand in the browser at left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTa6zf3e_9gV"
   },
   "source": [
    "Uploaded your saved checkpoint and unzip it.\n",
    "\n",
    "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
    "\n",
    "This will reset or start the tensorflow session as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fxL77nvAMAX",
    "outputId": "8938432a-3b86-4102-f32b-362721ecb897"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "if not sess:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)\n",
    "\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig-KVgkCDCKD"
   },
   "source": [
    "# Etcetera\n",
    "\n",
    "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIHiVP53FnsX"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmTXWNUygS5E"
   },
   "source": [
    "# License\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- Max's [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
    "- Original repo: [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple) by [Max Woolf](http://minimaxir.com). \n",
    "- Original [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) from Max."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.6 (py39)",
   "language": "python",
   "name": "tensorflow-gpu-2.6-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
